# Sistema de Web Scraping Multi-Prop√≥sito

Sistema centralizado de web scraping con men√∫ interactivo para ejecutar diferentes scrapers.

## üìã Descripci√≥n

Este sistema proporciona una interfaz de men√∫ unificada para ejecutar m√∫ltiples scrapers especializados. Actualmente incluye:

1. **OfferUp Scraper** - Extrae informaci√≥n de productos de OfferUp
2. **Clothing Image Scraper** - Descarga im√°genes de ropa de sitios web populares

## üöÄ Inicio R√°pido

### Instalaci√≥n

1. Instalar dependencias:
```bash
pip install -r requirements.txt
```

2. Ejecutar el men√∫ principal:
```bash
python main.py
```

## üìñ Uso del Sistema

### Men√∫ Principal

Al ejecutar `main.py`, se mostrar√° un men√∫ interactivo:

```
============================================================
               SISTEMA DE WEB SCRAPING
============================================================

Scrapers Disponibles:
------------------------------------------------------------
1. OfferUp Scraper
   ‚Üí Busca y extrae informaci√≥n de productos en OfferUp

2. Clothing Image Scraper
   ‚Üí Descarga im√°genes de ropa de sitios web populares

3. Salir
------------------------------------------------------------

Selecciona una opci√≥n:
```

### Opciones del Men√∫

#### 1. OfferUp Scraper

Busca productos en OfferUp con los siguientes par√°metros:

- **T√©rmino de b√∫squeda**: Producto a buscar (ej: iphone, laptop, fridge)
- **Ubicaci√≥n**: Ubicaci√≥n geogr√°fica (ej: San Diego, CA)
- **Precio m√≠nimo**: Precio m√≠nimo del producto
- **Precio m√°ximo**: Precio m√°ximo del producto
- **M√°ximo de items**: N√∫mero m√°ximo de resultados

**Ejemplo de uso:**
```
T√©rmino de b√∫squeda: laptop
Ubicaci√≥n: San Diego, CA
Precio m√≠nimo: 200
Precio m√°ximo: 800
N√∫mero m√°ximo de items: 30
```

**Salida:**
- `offerup_laptop.json` - Datos en formato JSON
- `offerup_laptop.csv` - Datos en formato CSV
- Screenshots y HTML guardados en carpeta `data/`

#### 2. Clothing Image Scraper

Descarga im√°genes de ropa de sitios web populares:

**Sitios disponibles:**
1. Unsplash - Fashion
2. Pexels - Clothing

**Par√°metros:**
- **Sitio**: Seleccionar el sitio fuente (1 o 2)
- **T√©rmino de b√∫squeda**: Tipo de ropa (ej: dress, jacket, fashion)
- **N√∫mero de im√°genes**: Cantidad m√°xima de im√°genes a descargar

**Ejemplo de uso:**
```
Sitio: 1 (Unsplash)
T√©rmino de b√∫squeda: dress
N√∫mero m√°ximo de im√°genes: 20
```

**Salida:**
- Carpeta `data/clothing_TIMESTAMP/images/` - Im√°genes descargadas
- `clothing_dress_info.json` - Metadatos de las im√°genes

## üèóÔ∏è Estructura del Proyecto

```
Selenium/
‚îú‚îÄ‚îÄ main.py                      # Men√∫ principal
‚îú‚îÄ‚îÄ scraper_manager.py           # Gestor de scrapers
‚îú‚îÄ‚îÄ config.py                    # Configuraci√≥n general
‚îú‚îÄ‚îÄ offerup_scraper.py          # Scraper de OfferUp
‚îú‚îÄ‚îÄ clothing_scraper.py         # Scraper de im√°genes de ropa
‚îú‚îÄ‚îÄ scraper.py                  # Clase base WebScraper
‚îú‚îÄ‚îÄ utils.py                    # Utilidades
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias
‚îú‚îÄ‚îÄ data/                       # Datos extra√≠dos
‚îÇ   ‚îú‚îÄ‚îÄ scraping_*/            # Resultados de OfferUp
‚îÇ   ‚îî‚îÄ‚îÄ clothing_*/            # Im√°genes de ropa
‚îî‚îÄ‚îÄ logs/                       # Archivos de log
```

## üîß Agregar Nuevos Scrapers

Para agregar un nuevo scraper al sistema:

### 1. Crear el archivo del scraper

Ejemplo: `my_scraper.py`

```python
"""
Mi nuevo scraper
"""
import logging
from scraper import WebScraper
from config import Config

logger = logging.getLogger(__name__)

class MyNewScraper:
    def __init__(self, headless=False):
        self.scraper = WebScraper(headless=headless)
    
    def scrape_data(self):
        # Implementar l√≥gica de scraping
        pass

def run_my_scraper():
    """Funci√≥n interactiva para ejecutar desde el men√∫"""
    print("\\n" + "="*50)
    print("MI NUEVO SCRAPER")
    print("="*50 + "\\n")
    
    # Obtener par√°metros del usuario
    param1 = input("Par√°metro 1: ").strip()
    
    # Ejecutar scraping
    scraper = MyNewScraper(headless=False)
    results = scraper.scrape_data()
    
    # Mostrar resultados
    if results:
        print(f"\\n‚úì Scraping completado!")
    else:
        print("\\n‚úó No se obtuvieron resultados")

if __name__ == "__main__":
    run_my_scraper()
```

### 2. Registrar el scraper en main.py

En la funci√≥n `setup_scrapers()` de [main.py](main.py), agregar:

```python
def setup_scrapers():
    manager = ScraperManager()
    
    # ... scrapers existentes ...
    
    # Registrar nuevo scraper
    manager.register_scraper(
        key='my_scraper',
        name='Mi Nuevo Scraper',
        description='Descripci√≥n de lo que hace mi scraper',
        execute_func=run_my_scraper  # Importar funci√≥n
    )
    
    return manager
```

### 3. Importar la funci√≥n en main.py

Al inicio de [main.py](main.py):

```python
from my_scraper import run_my_scraper
```

### 4. (Opcional) Agregar configuraci√≥n en config.py

En [config.py](config.py), dentro del diccionario `SCRAPERS`:

```python
SCRAPERS = {
    # ... scrapers existentes ...
    'my_scraper': {
        'name': 'Mi Nuevo Scraper',
        'description': 'Descripci√≥n detallada',
        'default_headless': False,
        # Par√°metros personalizados
        'param1': 'valor1'
    }
}
```

## üìä Formatos de Salida

### JSON
```json
[
    {
        "id": 1,
        "title": "Ejemplo",
        "price": "$100",
        "location": "San Diego, CA",
        "timestamp": "2025-12-19T10:30:00"
    }
]
```

### CSV
```csv
id,title,price,location,timestamp
1,Ejemplo,$100,"San Diego, CA",2025-12-19T10:30:00
```

## üîç Logs

Cada scraper genera su propio archivo de log:

- `main_scraper.log` - Log del men√∫ principal
- `offerup_scraper.log` - Log del scraper de OfferUp
- `clothing_scraper.log` - Log del scraper de ropa

## ‚öôÔ∏è Configuraci√≥n

Editar [config.py](config.py) para ajustar:

```python
class Config:
    # Navegador
    HEADLESS = True  # Ejecutar sin interfaz gr√°fica
    BROWSER = "chrome"  # chrome o firefox
    TIMEOUT = 10  # Tiempo de espera en segundos
    
    # Directorios
    OUTPUT_DIR = "data"
    LOG_DIR = "logs"
    
    # Delays
    MIN_DELAY = 1
    MAX_DELAY = 3
    SCROLL_PAUSE = 1.5
```

## üõ°Ô∏è Consideraciones Importantes

### OfferUp Scraper
- Sitio complejo que puede requerir inicio de sesi√≥n
- Puede encontrar CAPTCHAs
- Requiere t√©cnicas anti-detecci√≥n
- Los selectores pueden cambiar con actualizaciones del sitio

### Clothing Image Scraper
- Respeta los t√©rminos de servicio de los sitios
- Las URLs de im√°genes pueden cambiar
- Incluye delays para no sobrecargar servidores
- Verifica que tengas permiso para descargar im√°genes

## üìù Dependencias

```
selenium==4.16.0
webdriver-manager==4.0.1
pandas
python-dotenv==1.0.0
beautifulsoup4==4.12.2
openpyxl
requests==2.31.0
```

## ü§ù Contribuir

Para agregar nuevos scrapers o mejorar los existentes:

1. Crear el scraper siguiendo la estructura descrita
2. Probar exhaustivamente
3. Documentar par√°metros y salidas
4. Registrar en el sistema de men√∫s

## üìÑ Licencia

Este proyecto es de c√≥digo abierto para prop√≥sitos educativos.

## ‚ö†Ô∏è Disclaimer

Este software es solo para prop√≥sitos educativos. Aseg√∫rate de:
- Revisar y cumplir con los t√©rminos de servicio de cada sitio
- Respetar los archivos robots.txt
- No sobrecargar los servidores con peticiones excesivas
- Obtener permiso antes de scrapear sitios comerciales
